{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c33fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "from sklearn import preprocessing as pp\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label(df):\n",
    "    string_class = list(df[\"interaction\"].unique())\n",
    "\n",
    "    class_dic = {}\n",
    "\n",
    "    for i in range(len(string_class)):\n",
    "        class_dic[string_class[i]] = i\n",
    "\n",
    "    class_label = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        class_label.append(class_dic[df['interaction'][i]])\n",
    "        \n",
    "    with open('../Data/class_dic.pickle', 'wb') as fw:\n",
    "        pickle.dump(class_dic, fw)\n",
    "        \n",
    "    return class_label\n",
    "\n",
    "def get_embedded_matrix(embedding_dic_path, MAX_LENGTH):\n",
    "    with open(embedding_dic_path, 'rb') as fr:\n",
    "        embedded_dic_upper = pickle.load(fr)\n",
    "\n",
    "    embedded_dic = {}\n",
    "\n",
    "    for key in embedded_dic_upper.keys():\n",
    "        embedded_dic[key.lower()] = embedded_dic_upper[key]\n",
    "\n",
    "    del embedded_dic_upper\n",
    "\n",
    "    drugs = list(embedded_dic.keys())\n",
    "    vocab_size = len(embedded_dic)\n",
    "\n",
    "    drug_index = {}\n",
    "    i = 0\n",
    "\n",
    "    for key in embedded_dic.keys():\n",
    "        drug_index[key.lower()] = i\n",
    "        i = i + 1\n",
    "\n",
    "    count = []\n",
    "\n",
    "    for k in embedded_dic.keys():\n",
    "        count.append(len(embedded_dic[k]))\n",
    "\n",
    "    MAX_LENGTH = MAX_LENGTH\n",
    "\n",
    "    remove = []\n",
    "\n",
    "    for i in tqdm_notebook(embedded_dic.keys()):\n",
    "        if len(embedded_dic[i]) > MAX_LENGTH:\n",
    "            print(i)\n",
    "            remove.append(str(i))\n",
    "\n",
    "    for i in remove:\n",
    "        del embedded_dic[i]\n",
    "\n",
    "    for i in remove:\n",
    "        del drug_index[i]\n",
    "\n",
    "    embedded_list = []\n",
    "    for i in tqdm_notebook(embedded_dic.keys()):\n",
    "        embedded_list.append(embedded_dic[i])\n",
    "\n",
    "    pad = embedded_list[0][-1]\n",
    "\n",
    "    mx = 0\n",
    "\n",
    "    for i in embedded_list:\n",
    "        if len(i) >= mx:\n",
    "            mx = len(i)\n",
    "\n",
    "    for i in tqdm_notebook(range(len(embedded_list))):\n",
    "        while len(embedded_list[i]) < mx:\n",
    "            embedded_list[i].append(pad)\n",
    "\n",
    "    embedded_matrix = np.zeros(shape=(2080, MAX_LENGTH, 700))\n",
    "\n",
    "    for i in range(len(embedded_list)):\n",
    "        for j in range(len(embedded_list[i])):\n",
    "            embedded_list[i][j] = embedded_list[i][j].squeeze().tolist()\n",
    "\n",
    "    for i in range(len(embedded_list)):\n",
    "        embedded_list[i] = np.array(embedded_list[i])\n",
    "\n",
    "    for i in tqdm_notebook(range(len(embedded_matrix))):\n",
    "        embedded_matrix[i] = embedded_list[i]\n",
    "        \n",
    "    return embedded_matrix, remove, drug_index\n",
    "\n",
    "def clean_df(df_use, remove):\n",
    "    idx = []\n",
    "    for i in remove:\n",
    "        idx.append(list(df_use.index[df_use['DrugA'] == i]))\n",
    "    idx = sum(idx, [])\n",
    "    df_use = df_use.drop(idx, axis=0)\n",
    "\n",
    "    idx = []\n",
    "    for i in remove:\n",
    "        idx.append(list(df_use.index[df_use['DrugB'] == i]))\n",
    "    idx = sum(idx, [])    \n",
    "    df_cleaned = df_use.drop(idx, axis=0)\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "def get_embedded_df(df_cleaned, embedded_matrix, drug_index):\n",
    "    temp = []\n",
    "\n",
    "    for i in tqdm_notebook(range(len(df_cleaned))):\n",
    "        temp.append(embedded_matrix[drug_index[df_cleaned['DrugA'][i]]])\n",
    "    df_cleaned[\"DrugA\"] = temp\n",
    "    temp = []\n",
    "\n",
    "    for i in tqdm_notebook(range(len(df_cleaned))):\n",
    "        temp.append(embedded_matrix[drug_index[df_cleaned['DrugB'][i]]])\n",
    "    df_cleaned[\"DrugB\"] = temp\n",
    "\n",
    "    del temp\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "def cut_sample(count_sample_df, cut_thshold, embedded_df):\n",
    "    under_idx = count_sample_df[count_sample_df['count'] < cut_thshold].index\n",
    "    over_cut = embedded_df[~embedded_df.class_label.isin(under_idx)]\n",
    "    over_cut = sklearn.utils.shuffle(over_cut, random_state = random_seed)\n",
    "    \n",
    "    return over_cut\n",
    "\n",
    "def data_generate_save(over_thshold, MAX_LENGTH, test_size = 0.3, val_size = 0.3):\n",
    "    num_class = len(pd.DataFrame(over_thshold['class_label'].value_counts()))\n",
    "\n",
    "    x = over_thshold[[\"DrugA\", \"DrugB\"]]\n",
    "    y = over_thshold['class_label']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = random_seed) \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state = random_seed)\n",
    "    \n",
    "    train_idx = x_train.index.tolist()\n",
    "    val_idx = x_val.index.tolist()\n",
    "    test_idx = x_test.index.tolist()\n",
    "\n",
    "    train_A = np.zeros(shape=(len(x_train),MAX_LENGTH,700))\n",
    "    train_B = np.zeros(shape=(len(x_train),MAX_LENGTH,700))\n",
    "    test_A = np.zeros(shape=(len(x_test),MAX_LENGTH,700))\n",
    "    test_B = np.zeros(shape=(len(x_test),MAX_LENGTH,700))\n",
    "    val_A = np.zeros(shape=(len(x_val),MAX_LENGTH,700))\n",
    "    val_B = np.zeros(shape=(len(x_val),MAX_LENGTH,700))\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(train_idx))):\n",
    "        train_A[i] = x_train['DrugA'][train_idx[i]]\n",
    "\n",
    "    for i in tqdm_notebook(range(len(train_idx))):\n",
    "        train_B[i] = x_train['DrugB'][train_idx[i]]\n",
    "    \n",
    "    print('Saving training set...')\n",
    "    np.savez('../Generated_data/train_set.npz', train_A = train_A, train_B = train_B)\n",
    "    del train_A, train_B\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(test_idx))):\n",
    "        test_A[i] = x_test['DrugA'][test_idx[i]]\n",
    "\n",
    "    for i in tqdm_notebook(range(len(test_idx))):\n",
    "        test_B[i] = x_test['DrugB'][test_idx[i]]\n",
    "    \n",
    "    print('Saving test set...')\n",
    "    np.savez('../Generated_data/test_set.npz', test_A = test_A, test_B = test_B)\n",
    "    del test_A, test_B\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(val_idx))):\n",
    "        val_A[i] = x_val['DrugA'][val_idx[i]]\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(val_idx))):\n",
    "        val_B[i] = x_val['DrugB'][val_idx[i]]\n",
    "    \n",
    "    print('Saving validation set...')\n",
    "    np.savez('../Generated_data/val_set.npz', val_A = val_A, val_B = val_B)\n",
    "    del val_A, val_B\n",
    "    \n",
    "    one_hot_train = pd.get_dummies(y_train)\n",
    "    one_hot_test = pd.get_dummies(y_test)\n",
    "    one_hot_val = pd.get_dummies(y_val)\n",
    "    \n",
    "    print('Saving one hot data...')\n",
    "    one_hot_test.to_csv('../Generated_data/one_hot_test.csv', header = True, index = True)\n",
    "    one_hot_val.to_csv('../Generated_data/one_hot_val.csv', header = True, index = True)\n",
    "    one_hot_train.to_csv('../Generated_data/one_hot_train.csv', header = True, index = True)\n",
    "    \n",
    "def generate_data(max_sample_num, input_sequence_length, df):\n",
    "    class_label = get_class_label(df)\n",
    "    df_use = pd.concat([df.iloc[:,:2], pd.DataFrame(class_label, columns=[\"class_label\"])], axis=1)\n",
    "    embedded_matrix, remove, drug_index = get_embedded_matrix(embedding_dic_path, input_sequence_length)\n",
    "    df_use['DrugA'] = df_use['DrugA'].apply(lambda x: x.lower())\n",
    "    df_use['DrugB'] = df_use['DrugB'].apply(lambda x: x.lower())\n",
    "    df_cleaned = clean_df(df_use, remove)\n",
    "    df_cleaned.to_csv('../Generated_data/base_df.csv')\n",
    "    embedded_df = get_embedded_df(df_cleaned, embedded_matrix, drug_index)\n",
    "    count_sample_df = pd.DataFrame(embedded_df['class_label'].value_counts())\n",
    "    over_thshold = cut_sample(count_sample_df, max_sample_num, embedded_df)\n",
    "    data_generate_save(over_thshold, input_sequence_length)\n",
    "    \n",
    "random_seed = 0\n",
    "# 클래스 레이블 그루핑 완료된 데이터프레임\n",
    "df = pd.read_csv('../Data/DDI.csv')\n",
    "input_sequence_length = 128\n",
    "max_sample_num = 10000\n",
    "embedding_dic_path = '../Data/drug_vec_dic_BioSentVec_sent.pickle'\n",
    "\n",
    "generate_data(max_sample_num, input_sequence_length, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDI_39",
   "language": "python",
   "name": "ddi_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
